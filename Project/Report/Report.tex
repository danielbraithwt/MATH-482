\documentclass{article}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\title{%
	MATH 482\\
	\large Matrix Factorisation Project
}
\author{Daniel Braithwaite}


\begin{document}

\maketitle

\section{Introduction}
To dicuss the idea of matrix factorisation and methods to solve it first we must understand the motivation for wanting to solve such a problem. In the case of the Netflicks challenge the problem was to build a system to recomend movies to users. We have this very large martix $R$ with the rows corosponding to a user and a column corosponding to a movie. The entry $R_{i,j}$ is the rating that user i gave movie j, in practice we would find that a very small percentage of this matrix would be filled in. To make recomendations we would like to predict the ratings which a user might give a movie which they havent watched.\\

\section{Solution 1: $R = U * M$}
The first soluton we consider is that R (an $u x m$ matrix) is actually the product of two smaller matricies $U$ and $M$. Where $U$ (a $u x k$ matrix) represents the users in some latent feature space and $M$ (a $m x k$ matrix) represents the movies in the latent feature space. We consider $M_{i,j}$ to be the ammount movie $i$ has feature $j$, likewise we consider $U_{i,j}$ to be how much user i is interested in movies with feature j. Then we can take the rating user i gives movie j to be $R_{i,j} = row(U, i)^T \cdot row(M, j)$. Now the problem becomes how do we learn these matricies $U$ and $M$.\\

We consider the folowing optimizimation problem, where $G$ contains all pairs $(i,j)$ for which we know $R_{i,j}$

\begin{equation*}
\begin{aligned}
& \underset{U, M}{\text{min}}
& & \sum_{(i,j) \in G} (R_{i,j} - row(U, i)^T \cdot row(M, j))^2  \\
\end{aligned}
\end{equation*}

This optimization problem can be solved with gradient decent

\end{document}